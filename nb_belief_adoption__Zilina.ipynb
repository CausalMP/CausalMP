{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292fc04c",
   "metadata": {},
   "source": [
    "# Belief Adoption Model - Zilina with N=42971\n",
    "\n",
    "This notebook demonstrates how to use the causalmp library to analyze counterfactual scenarios. We'll show how to:\n",
    "\n",
    "- Set up simulation environments\n",
    "\n",
    "- Generate experimental data\n",
    "\n",
    "- Estimate counterfactual evolution under different intervention scenarios \n",
    "\n",
    "- Visualize results with informative plots\n",
    "\n",
    "The notebook features parallel processing capabilities to speed up multiple experimental runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb781da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork', force=True)\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import causalmp components\n",
    "from causalmp import cmp_estimator, cmp_simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90df6c96",
   "metadata": {},
   "source": [
    "# 1. Environment Configuration\n",
    "This environment models how beliefs spread through the Topolcany social network (18,246 nodes) under different treatment interventions, implementing Montanari and Saberi's (2010) cascade model. The experimental units are individual network members, with binary outcomes representing opinion adoption (1 for Opinion A, 0 for Opinion B) in each period. The treatment represents a campaign aimed at increasing Opinion A adoption, with effectiveness varying based on demographic factors from Pokec social network profiles. The opinion evolution follows a network-based coordination game where adoption probability depends on neighbor configurations and relative payoffs, creating complex patterns of direct and indirect influence that propagate through the moderately-sized community's social connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc723c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define environment parameters for the Belief Adoption Model\n",
    "environment = {\n",
    "    'N': 42971,  # Number of nodes (Zilina network)\n",
    "    'setting': \"Belief Adoption Model\",\n",
    "    'design': [0, 0.1, 0.2, 0.5],  # Treatment probabilities at different stages\n",
    "    'stage_time_blocks': [1, 3, 5, 7],  # Time periods for different stages\n",
    "    'desired_design_1': [0, 0],  # Control scenario (no intervention)\n",
    "    'desired_design_2': [0, 1],  # Treatment scenario (full intervention)\n",
    "    'desired_stage_time_blocks': [1, 7],  # Time blocks for counterfactual scenarios\n",
    "    'tau': 1  # Treatment effect coefficient \n",
    "}\n",
    "\n",
    "data_path = None # Path to pre-generated data files (None means data will be freshly generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e7126",
   "metadata": {},
   "source": [
    "# 2. Estimation Parameters\n",
    "Next, we configure the parameters for our counterfactual estimation models. These parameters control model complexity, regularization, and validation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7440207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation parameters\n",
    "n_validation_batch = 2  # Number of validation batches for model selection\n",
    "time_blocks = [(0, 3), (3, 5), (5, 7)] # time blocks for validation in the format [(start1, end1), (start2, end2), ...]\n",
    "N = environment['N']\n",
    "\n",
    "# Detrending options\n",
    "detrending_options = [True]  # Whether to detrend the data before estimation\n",
    "\n",
    "# Detrending parameters (used only if detrending=True)\n",
    "detrending_param_ranges = {\n",
    "    'n_lags_Y_range': [1],  # Number of outcome lags\n",
    "    'interaction_term_p_range': [None],  # Interaction term for population-level outcomes and treatment\n",
    "    'interaction_term_u_range': [1],  # Interaction term for unit-level outcomes and treatment\n",
    "    'n_batch_range': [1],  # Number of batches\n",
    "    'batch_size_range': [N],  # Batch size\n",
    "    'ridge_alpha_range': [1e-4]  # Regularization strength\n",
    "}\n",
    "\n",
    "# Main estimation parameters\n",
    "main_param_ranges = {\n",
    "    'n_lags_Y_range': [1],  # Number of outcome lags\n",
    "    'n_lags_W_range': [1],  # Number of treatment lags\n",
    "    'moment_order_p_Y_range': [1],  # Moment order for population-level outcomes\n",
    "    'moment_order_p_W_range': [1],  # Moment order for population-level treatments,  \n",
    "    'moment_order_u_Y_range': [1],  # Moment order for unit-level outcomes\n",
    "    'moment_order_u_W_range': [1],  # Moment order for unit-level treatments, \n",
    "    'interaction_term_p_range': [None],  # Interaction term for population-level outcomes and treatment\n",
    "    'interaction_term_u_range': [None, 1],  # Interaction term for unit-level outcomes and treatment\n",
    "    'n_batch_range': [100, 500, 1000],  # Number of batches\n",
    "    'batch_size_range': [int(0.05 * N), int(0.1 * N), int(0.2 * N), int(0.3 * N), int(0.5 * N)],  # Batch size\n",
    "    'ridge_alpha_range': [1e-4, 1e-2, 1, 100]  # Regularization strength\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5239ca3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. Single Run Function\n",
    "Here we define a function to run a single experiment. This function:\n",
    "\n",
    "- Generates data using the simulator\n",
    "\n",
    "- Runs the counterfactual cross-validation to choose the best model and configuration\n",
    "\n",
    "- Estimates counterfactuals for the desired scenarios\n",
    "\n",
    "- Computes treatment effects and organizes results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158dd8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_experiment(run_id, environment, main_param_ranges, \n",
    "                          detrending_options, detrending_param_ranges,\n",
    "                          n_validation_batch, time_blocks,\n",
    "                          visualize_ccv=False, data_path=None):\n",
    "    \"\"\"\n",
    "    Run a single experiment with the Belief Adoption Model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    run_id : int\n",
    "        Identifier for this experimental run\n",
    "    environment : dict\n",
    "        Environment parameters\n",
    "    main_param_ranges : dict\n",
    "        Parameter ranges for the main estimator\n",
    "    detrending_options : list\n",
    "        Whether to use detrending\n",
    "    detrending_param_ranges : dict\n",
    "        Parameter ranges for detrending\n",
    "    n_validation_batch : int\n",
    "        Number of validation batches\n",
    "    time_blocks : list of tuples\n",
    "        Pre-defined time blocks for validation in the format [(start1, end1), (start2, end2), ...]\n",
    "    visualize_ccv : bool\n",
    "        Whether to visualize cross-validation results\n",
    "    data_path : str or Path\n",
    "        If provided, path to read the data instead of generating it\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (observed_outcomes_df, CFEs_df, TTEs_df) containing results\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Run {run_id+1} ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(run_id)\n",
    "    \n",
    "    # Step 1: Generate data using the simulator or load data\n",
    "    if data_path is None:\n",
    "        print(\"Generating data...\")\n",
    "        W, Y, desired_W_1, desired_Y_1, desired_W_2, desired_Y_2 = cmp_simulator(\n",
    "            environment=environment,\n",
    "            seed=run_id\n",
    "        )\n",
    "    else:\n",
    "        print(\"Loading data...\")\n",
    "        W, Y, desired_W_1, desired_Y_1, desired_W_2, desired_Y_2 = load_data(\n",
    "            environment=environment,\n",
    "            data_path=data_path,\n",
    "            run_id=run_id\n",
    "        )\n",
    "    print(f\"Data shapes - W: {W.shape}, Y: {Y.shape}\")\n",
    "    \n",
    "    # Step 2: Estimate counterfactuals\n",
    "    print(\"Estimating counterfactuals...\")\n",
    "    predictions_1, predictions_2, best_config, best_model_terms = cmp_estimator(\n",
    "        Y=Y,\n",
    "        W=W,\n",
    "        desired_W=desired_W_1,\n",
    "        desired_W_2=desired_W_2,\n",
    "        main_param_ranges=main_param_ranges,\n",
    "        time_blocks=time_blocks,\n",
    "        n_validation_batch=n_validation_batch,\n",
    "        detrending_options=detrending_options,\n",
    "        detrending_param_ranges=detrending_param_ranges,\n",
    "        visualize_ccv=visualize_ccv,\n",
    "        return_model_terms=True\n",
    "    )\n",
    "        \n",
    "    # Step 4: Prepare results dataframes\n",
    "    # Ground truth from simulation\n",
    "    desired_CFE_1 = np.mean(desired_Y_1, axis=0)\n",
    "    desired_CFE_2 = np.mean(desired_Y_2, axis=0)\n",
    "    TTE_ground_truth = desired_CFE_2 - desired_CFE_1\n",
    "    \n",
    "    # Estimated treatment effects\n",
    "    TTE_estimated = predictions_2 - predictions_1\n",
    "    \n",
    "    # Calculate Difference-in-Means and Horvitz-Thompson estimators\n",
    "    from causalmp import dinm_estimate, ht_estimate, basic_cmp_estimate\n",
    "    TTE_dim = dinm_estimate(Y, W)\n",
    "    TTE_ht = ht_estimate(Y, W, environment[\"stage_time_blocks\"], environment[\"design\"])\n",
    "    TTE_basic_cmp = basic_cmp_estimate(Y, W)\n",
    "    \n",
    "    # Create observed outcomes dataframe\n",
    "    observed_mean = np.mean(Y, axis=0)\n",
    "    observed_std = np.std(Y, axis=0)\n",
    "    \n",
    "    observed_outcomes_df = pd.DataFrame([\n",
    "        *[{'Time': t, 'outcome': observed_mean[t], 'run': run_id, 'label': 'mean'} \n",
    "          for t in range(len(observed_mean))],\n",
    "        *[{'Time': t, 'outcome': observed_std[t], 'run': run_id, 'label': 'stdev'} \n",
    "          for t in range(len(observed_std))]\n",
    "    ])\n",
    "    \n",
    "    # Create CFEs dataframe\n",
    "    CFEs_df = pd.DataFrame([\n",
    "        *[{'Time': t, 'CFE': predictions_1[t], 'run': run_id, \n",
    "           'type': 'CFE(0)', 'label': 'Causal-MP'} \n",
    "          for t in range(len(predictions_1))],\n",
    "        *[{'Time': t, 'CFE': predictions_2[t], 'run': run_id, \n",
    "           'type': 'CFE(1)', 'label': 'Causal-MP'} \n",
    "          for t in range(len(predictions_2))],\n",
    "        *[{'Time': t, 'CFE': desired_CFE_1[t], 'run': run_id, \n",
    "           'type': 'CFE(0)', 'label': 'Ground Truth'} \n",
    "          for t in range(len(desired_CFE_1))],\n",
    "        *[{'Time': t, 'CFE': desired_CFE_2[t], 'run': run_id, \n",
    "           'type': 'CFE(1)', 'label': 'Ground Truth'} \n",
    "          for t in range(len(desired_CFE_2))]\n",
    "    ])\n",
    "    \n",
    "    # Create TTEs dataframe\n",
    "    TTEs_df = pd.DataFrame([\n",
    "        *[{'Time': t, 'TTE': TTE_ground_truth[t], 'run': run_id, \n",
    "           'label': 'GT'} \n",
    "          for t in range(len(TTE_ground_truth))],\n",
    "        *[{'Time': t, 'TTE': TTE_estimated[t], 'run': run_id, \n",
    "           'label': 'CMP'} \n",
    "          for t in range(len(TTE_estimated))],\n",
    "        *[{'Time': t, 'TTE': TTE_dim[t], 'run': run_id, \n",
    "           'label': 'DM'} \n",
    "          for t in range(len(TTE_dim))],\n",
    "        *[{'Time': t, 'TTE': TTE_ht[t], 'run': run_id, \n",
    "           'label': 'HT'} \n",
    "          for t in range(len(TTE_ht))],\n",
    "        *[{'Time': t, 'TTE': TTE_basic_cmp[t], 'run': run_id, \n",
    "           'label': 'bCMP'} \n",
    "          for t in range(len(TTE_basic_cmp))]\n",
    "    ])\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Run {run_id+1} completed in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return observed_outcomes_df, CFEs_df, TTEs_df, best_config, best_model_terms\n",
    "\n",
    "def load_data(environment, data_path, run_id):\n",
    "        \"\"\"Load data from files.\"\"\"\n",
    "        from pathlib import Path\n",
    "        # Extract parameters\n",
    "        N = environment[\"N\"]\n",
    "        T = environment[\"stage_time_blocks\"][-1]\n",
    "        \n",
    "        file_paths = {\n",
    "            'Y': Path(data_path) / f'seed{run_id}/experiment_n{N}_t{T}_seed{run_id}_panel_data.csv',\n",
    "            'Y_1': Path(data_path) / f'seed{run_id}/treatment_n{N}_t{T}_seed{run_id}_panel_data.csv',\n",
    "            'Y_0': Path(data_path) / f'seed{run_id}/control_n{N}_t{T}_seed{run_id}_panel_data.csv',\n",
    "            'W': Path(data_path) / f'seed{run_id}/experiment_n{N}_t{T}_seed{run_id}_treatment_data.csv',\n",
    "            'W_1': Path(data_path) / f'seed{run_id}/treatment_n{N}_t{T}_seed{run_id}_treatment_data.csv',\n",
    "            'W_0': Path(data_path) / f'seed{run_id}/control_n{N}_t{T}_seed{run_id}_treatment_data.csv'\n",
    "        }\n",
    "        \n",
    "        # Check for missing files\n",
    "        missing = [f for f in file_paths.values() if not f.exists()]\n",
    "        if missing:\n",
    "            raise FileNotFoundError(f\"Missing files: {missing}\")\n",
    "        \n",
    "        # Read all files\n",
    "        data = {k: pd.read_csv(v).iloc[:, 0:].to_numpy() for k, v in file_paths.items()}\n",
    "        \n",
    "        return (data['W'], data['Y'], data['W_0'], data['Y_0'], data['W_1'], data['Y_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effff0e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4. Multiple Runs Function\n",
    "This function orchestrates multiple experiment runs, with support for parallel processing to speed up computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_experiments(n_runs, n_processes=None, data_path=None, \n",
    "                             return_model_terms=True, **experiment_params):\n",
    "    \"\"\"\n",
    "    Run multiple experimental runs, either sequentially or in parallel.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_runs : int\n",
    "        Number of experimental runs\n",
    "    n_processes : int or None\n",
    "        Number of parallel processes (None or 1 for sequential)\n",
    "    **experiment_params : dict\n",
    "        Parameters to pass to each experiment\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (all_observed_outcomes, all_CFEs, all_TTEs) as DataFrames\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize combined DataFrames\n",
    "    all_observed_outcomes = pd.DataFrame()\n",
    "    all_CFEs = pd.DataFrame()\n",
    "    all_TTEs = pd.DataFrame()\n",
    "    \n",
    "    # Sequential execution\n",
    "    if n_processes is None or n_processes == 1:\n",
    "        print(f\"\\nRunning {n_runs} experiments sequentially...\")\n",
    "        for run_id in tqdm(range(n_runs)):\n",
    "            observed_df, cfes_df, ttes_df, best_config, best_model_terms = run_single_experiment(\n",
    "                data_path=data_path, run_id=run_id, **experiment_params\n",
    "            )\n",
    "            \n",
    "            # Display best configuration\n",
    "            if return_model_terms:\n",
    "                from causalmp import ResultVisualizer\n",
    "                visualizer = ResultVisualizer()\n",
    "                visualizer.display_best_configuration(best_config, best_model_terms)\n",
    "            \n",
    "            # Concatenate results\n",
    "            all_observed_outcomes = pd.concat([all_observed_outcomes, observed_df], ignore_index=True)\n",
    "            all_CFEs = pd.concat([all_CFEs, cfes_df], ignore_index=True)\n",
    "            all_TTEs = pd.concat([all_TTEs, ttes_df], ignore_index=True)\n",
    "            \n",
    "    # Parallel execution\n",
    "    else:\n",
    "        print(f\"\\nRunning {n_runs} experiments in parallel with {n_processes} processes...\")\n",
    "        n_processes = min(n_processes, mp.cpu_count())\n",
    "        \n",
    "        # Add collection for best configs and model terms\n",
    "        best_configs_dict = {}\n",
    "        best_model_terms_dict = {}\n",
    "        \n",
    "        # Create partial function with fixed experiment parameters\n",
    "        partial_run = partial(run_single_experiment, data_path=data_path, **experiment_params)\n",
    "        \n",
    "        # Run parallel processing\n",
    "        with mp.Pool(processes=n_processes) as pool:\n",
    "            results = list(tqdm(pool.imap(partial_run, range(n_runs)), total=n_runs))\n",
    "            \n",
    "            # Process results\n",
    "            for i, (observed_df, cfes_df, ttes_df, best_config, best_model_terms) in enumerate(results):\n",
    "                all_observed_outcomes = pd.concat([all_observed_outcomes, observed_df], ignore_index=True)\n",
    "                all_CFEs = pd.concat([all_CFEs, cfes_df], ignore_index=True)\n",
    "                all_TTEs = pd.concat([all_TTEs, ttes_df], ignore_index=True)\n",
    "                best_configs_dict[i] = best_config\n",
    "                best_model_terms_dict[i] = best_model_terms\n",
    "            \n",
    "        # Display best configuration\n",
    "        if return_model_terms:\n",
    "            from causalmp import ResultVisualizer\n",
    "            visualizer = ResultVisualizer()\n",
    "            for i in range(n_runs):\n",
    "                visualizer.display_best_configuration(best_configs_dict[i],\n",
    "                                                      best_model_terms_dict[i])\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nAll experiments completed in {total_time:.2f} seconds\")\n",
    "    print(f\"Average time per run: {total_time/n_runs:.2f} seconds\")\n",
    "    \n",
    "    return all_observed_outcomes, all_CFEs, all_TTEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3564aaf5",
   "metadata": {},
   "source": [
    "# 5. Run the Experiments\n",
    "Now we'll execute the experiments with our defined parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-configurable parameters\n",
    "n_runs = 100  # Number of experimental runs\n",
    "n_processes = 100  # Number of parallel processes (None or 1 for sequential execution)\n",
    "\n",
    "# Run the experiments\n",
    "all_observed_outcomes, all_CFEs, all_TTEs = run_multiple_experiments(\n",
    "    n_runs=n_runs,\n",
    "    n_processes=n_processes,\n",
    "    return_model_terms=True,\n",
    "    environment=environment,\n",
    "    main_param_ranges=main_param_ranges,\n",
    "    detrending_options=detrending_options,\n",
    "    detrending_param_ranges=detrending_param_ranges,\n",
    "    n_validation_batch=n_validation_batch,\n",
    "    time_blocks=time_blocks,\n",
    "    data_path=data_path,\n",
    "    visualize_ccv=False\n",
    ")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(f\"Number of runs: {n_runs}\")\n",
    "print(f\"Unique runs in data: {len(all_observed_outcomes['run'].unique())}\")\n",
    "print(f\"Time periods: {all_observed_outcomes['Time'].max() + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72107180",
   "metadata": {},
   "source": [
    "# 6. Visualize and Interpret Results\n",
    "Finally, we'll visualize the results and interpret our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ResultVisualizer from causalmp\n",
    "from causalmp import ResultVisualizer\n",
    "\n",
    "# Set plot styling\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create a visualizer instance\n",
    "visualizer = ResultVisualizer()\n",
    "\n",
    "# Visualize the results using the built-in visualizer\n",
    "visualizer.plot_results(\n",
    "    Observed_outcomes=all_observed_outcomes,\n",
    "    CFEs=all_CFEs,\n",
    "    TTEs=all_TTEs,\n",
    "    # Optional parameters:\n",
    "    filename=\"belief_adoption_Z.pdf\",  # Uncomment to save the plot to a file\n",
    "    # layout=\"1x4\",  # Options: \"1x4\" or \"2x2\"\n",
    "    y_lim=(0.0, 0.031),  # Optional y-axis limits for TTE plot\n",
    "    # x_ticks=list(range(0, environment['stage_time_blocks'][-1] + 1, 5))  # Optional custom x-ticks\n",
    "    n_periods_for_tte=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab0d79-c834-46d8-83f5-6844ebb34b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with a specific size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Your original plot code\n",
    "sns.lineplot(data=all_TTEs,\n",
    "             x='Time',\n",
    "             y='TTE',\n",
    "             errorbar=('pi', 95),\n",
    "             hue='label',\n",
    "             style='label')\n",
    "\n",
    "plt.ylim(bottom=0, top=40)  \n",
    "\n",
    "# Apply layout adjustments\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
